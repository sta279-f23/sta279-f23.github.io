---
title: "Lecture 2"
format: 
  revealjs:
    theme: theme.scss
editor: visual
editor_options: 
  chunk_output_type: console
---


## Warm-up question

* A roulette wheel has 38 slots numbered 00, 0, and 1--36. Two are green, 18 are red, and 18 are black.
* If a gambler bets based on color, the return on a \$1 bet is \$2
* A gambler has \$50, and will continuously bet \$1 on red until they double their money (have \$100) or lose the money they came with
* What is the probability the gambler doubles their money?

**Question:** Work with your neighbor to discuss the following question:

* Without calculating probabilities, how could you design an experiment to estimate this probability?


## Designing an experiment


## Step 1: representing the roulette wheel

```{r, echo=T}
wheel <- c(rep("green", 2), rep("black", 18), rep("red", 18))

wheel
```

* `rep` repeats a value a specified number of times
* `c()` combines vectors into a single vector

## Step 2: spin the wheel!

```{r, echo=T}
spin <- sample(wheel, size = 1)

spin
```

## Step 3: change in money

```{r, echo=T}
money <- 50
spin <- sample(wheel, size = 1)

money <- ifelse(spin == "red", money + 1, money - 1)

spin
money
```

* if the result was red, gain a dollar
* otherwise, lose a dollar

## Step 4: keep spinning

The gambler continues to bet until they have \$0 or \$100. 

**Question:** Is a `for` loop appropriate for iterating the betting process?

## Step 4: keep spinning

```{r, echo = T}
money <- 50 # starting money

while(money > 0 & money < 100){
  spin <- sample(wheel, size = 1)
  money <- ifelse(spin == "red", money + 1, money - 1)
}

money
```

* `while` loop: repeat the process until the condition is true

## Step 5: repeat the process

```{r, echo = T, eval=F}
set.seed(279)

nsim <- 1000
results <- rep(NA, nsim)

for(i in 1:nsim){
  money <- 50 # starting money

  while(money > 0 & money < 100){
    spin <- sample(wheel, size = 1)
    money <- ifelse(spin == "red", money + 1, money - 1)
  }
  
  results[i] <- ...
}
```

* What should I check at each iteration?

## Step 5: repeat the process

```{r, echo = T}
set.seed(279)

nsim <- 1000
results <- rep(NA, nsim)

for(i in 1:nsim){
  money <- 50 # starting money

  while(money > 0 & money < 100){
    spin <- sample(wheel, size = 1)
    money <- ifelse(spin == "red", money + 1, money - 1)
  }
  
  results[i] <- money == 100
}

mean(results)
```


## A new question

In STA 112, you learned about the simple linear regression model:

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

**Question:** What assumptions does this model make?

## A new question

In STA 112, you learned about the simple linear regression model:

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

**Question:** How important is it that $\varepsilon_i \sim N(0, \sigma^2)$? Does it matter if the errors are *not* normal?

## Activity

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

**Activity:** With a neighbor, brainstorm how you could use simulation to assess the importance of the normality assumption (you do not need to write code!).

* How would you simulate data?
* What result would you measure for each run of the simulation?


## Class activity

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

How would you study the importance of the normality assumption?


## Simulating data

To start, simulate data for which the normality assumption holds:

```{r, echo=T}
n <- 100 # sample size
beta0 <- 0.5 # intercept
beta1 <- 1 # slope

x <- runif(n, min=0, max=1)
noise <- rnorm(n, mean=0, sd=1)
y <- beta0 + beta1*x + noise
```

* `runif(n, min=0, ,max=1)` samples $X_i$ uniformly between 0 and 1
* `rnorm(n, mean=0, sd=1)` samples $\varepsilon_i \sim N(0, 1)$

## Fit a model

```{r, echo=T}
n <- 100 # sample size
beta0 <- 0.5 # intercept
beta1 <- 1 # slope

x <- runif(n, min=0, max=1)
noise <- rnorm(n, mean=0, sd=1)
y <- beta0 + beta1*x + noise

lm_mod <- lm(y ~ x)
lm_mod
```

## Calculate confidence interval

```{r, echo=T}
lm_mod <- lm(y ~ x)

ci <- confint(lm_mod, "x", level = 0.95)
ci
```

* **Question:** How can we check whether the confidence interval contains the true $\beta_1$?


## Calculate confidence interval

```{r, echo=T}
lm_mod <- lm(y ~ x)

ci <- confint(lm_mod, "x", level = 0.95)
ci
```

* **Question:** How can we check whether the confidence interval contains the true $\beta_1$?

```{r, echo=T}
ci[1] < 1 & ci[2] > 1
```

## Repeat!

```{r, echo=T, eval=F}
nsim <- 1000
n <- 100 # sample size
beta0 <- 0.5 # intercept
beta1 <- 1 # slope
results <- rep(NA, nsim)

for(i in 1:nsim){
  x <- runif(n, min=0, max=1)
  noise <- rnorm(n, mean=0, sd=1)
  y <- beta0 + beta1*x + noise

  lm_mod <- lm(y ~ x)
  ci <- confint(lm_mod, "x", level = 0.95)
  
  results[i] <- ci[1] < 1 & ci[2] > 1
}
mean(results)
```

* What fraction of the time should the confidence interval contain $\beta_1$?

## Repeat!

```{r, echo=T}
nsim <- 1000
n <- 100 # sample size
beta0 <- 0.5 # intercept
beta1 <- 1 # slope
results <- rep(NA, nsim)

for(i in 1:nsim){
  x <- runif(n, min=0, max=1)
  noise <- rnorm(n, mean=0, sd=1)
  y <- beta0 + beta1*x + noise

  lm_mod <- lm(y ~ x)
  ci <- confint(lm_mod, "x", level = 0.95)
  
  results[i] <- ci[1] < 1 & ci[2] > 1
}
mean(results)
```

* What should we do next?

