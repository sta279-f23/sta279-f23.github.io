---
title: "Lecture 3: Designing simulations"
format: 
  revealjs:
    theme: theme.scss
editor: visual
editor_options: 
  chunk_output_type: console
---

## Class activity

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

That is, how important is the assumption that $\varepsilon_i \sim N(0, \sigma^2)$?

Continue simulation from last time, but experiment with different values of $n$ and different distributions for the noise term.

[https://sta279-f23.github.io/class_activities/ca_lecture_3.html](https://sta279-f23.github.io/class_activities/ca_lecture_3.html)

## Class activity

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

How does confidence interval coverage change when you change the distribution of $\varepsilon_i$?

## Class activity

```{r, echo=T}
nsim <- 1000
n <- 100 # sample size
beta0 <- 0.5 # intercept
beta1 <- 1 # slope
results <- rep(NA, nsim)

for(i in 1:nsim){
  x <- runif(n, min=0, max=1)
  noise <- rchisq(n, 1)
  y <- beta0 + beta1*x + noise

  lm_mod <- lm(y ~ x)
  ci <- confint(lm_mod, "x", level = 0.95)
  
  results[i] <- ci[1] < 1 & ci[2] > 1
}
mean(results)
```

## ADEMP: A useful framework for simulation studies

* **Aims:** Why are we doing the study?
* **Data generation:** How are the data simulated?
* **Estimand/target:** What are we estimating for each simulated dataset?
* **Methods:** What methods are we using for model fitting, estimation, etc?
* **Performance measures:** How do we measure performance of our chosen methods?

## ADEMP

For the normal errors simulation study:

* **Aims:** 
* **Data generation:** 
* **Estimand/target:** 
* **Methods:** 
* **Performance measures:**


